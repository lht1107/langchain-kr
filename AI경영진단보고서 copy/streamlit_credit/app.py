# fmt: off
import os
import sys
import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import requests
import json
import time
from datetime import datetime
import plotly.graph_objects as go
from typing import Dict
import xgboost as xgb


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì‹ ìš©ë¶„ì„ ë¦¬í¬íŠ¸",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
DB_PATH = os.path.join(project_root, "database", "sqlite_credit_cache.db")
from core.config import settings
from utils import load_prompt
# fmt: on
# SQLite ì—°ê²° í•¨ìˆ˜


@st.cache_data(show_spinner=False)
def fetch_credit_query(company_index: str, analysis_type: str) -> dict:
    """
    Fetch credit_query results from API and cache them.
    """
    try:

        payload = {
            "company_index": company_index,
            "analysis_type": analysis_type
        }

        response = requests.post(
            f"http://127.0.0.1:8000/credit_query/",
            json=payload
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching data from credit_query API: {e}")
        return {}


# ê²Œì´ì§€ ì°¨íŠ¸ í•¨ìˆ˜
@st.cache_resource
def create_gauge_chart(current_analysis):
    proba = current_analysis["proba"]
    grade = current_analysis["grade"]

    fig_gauge = go.Figure(go.Indicator(
        mode="gauge+number",
        value=proba,
        title={'text': f"Credit Grade: {grade}"},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': "black"},
            'steps': [
                {'range': [0, 5], 'color': "lightgreen", 'name': 'AAA'},
                {'range': [5.01, 10], 'color': "green", 'name': 'AA'},
                {'range': [10.01, 15], 'color': "yellowgreen", 'name': 'A'},
                {'range': [15.01, 20], 'color': "yellow", 'name': 'BBB'},
                {'range': [20.01, 30], 'color': "orange", 'name': 'BB'},
                {'range': [30.01, 40], 'color': "darkorange", 'name': 'B'},
                {'range': [40.01, 50], 'color': "orangered", 'name': 'CCC'},
                {'range': [50.01, 60], 'color': "red", 'name': 'CC'},
                {'range': [60.01, 100], 'color': "darkred", 'name': 'C'}
            ],
            'threshold': {
                'line': {'color': "black", 'width': 4},
                'thickness': 0.75,
                'value': proba
            }
        }
    ))

    fig_gauge.update_layout(
        width=400,
        height=300,
        margin=dict(t=50, b=50, l=50, r=50)
    )

    return fig_gauge, proba, grade

# ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ í•¨ìˆ˜


@st.cache_resource
def create_bar_charts(current_analysis):
    top_increasing = current_analysis["top_increasing"]
    top_decreasing = current_analysis["top_decreasing"]

    # ìƒìŠ¹ ìš”ì¸ ë°ì´í„°
    increasing_features = [d["label"] for d in top_increasing]
    increasing_values = [d["shap_value"] for d in top_increasing]

    # í•˜ë½ ìš”ì¸ ë°ì´í„°
    decreasing_features = [d["label"] for d in top_decreasing]
    decreasing_values = [-abs(d["shap_value"]) for d in top_decreasing]

    # ë°ì´í„°ë¥¼ í•©ì¹¨
    features = decreasing_features + increasing_features
    values = decreasing_values + increasing_values

    # ì •ë ¬: ê°’ ê¸°ì¤€ìœ¼ë¡œ (ì˜¤ë¦„ì°¨ìˆœ) ì •ë ¬
    sorted_data = sorted(zip(features, values), key=lambda x: x[1])
    sorted_features, sorted_values = zip(*sorted_data)

    # íˆ´íŒ ë°ì´í„° ì¶”ê°€ (SHAP ê°’ë§Œ í‘œì‹œ)
    tooltips = [f"{value:.2f}" for value in sorted_values]

    # ê·¸ë˜í”„ ìƒì„±
    fig_bar = go.Figure()

    fig_bar.add_trace(go.Bar(
        x=sorted_values,
        y=sorted_features,
        orientation='h',
        marker=dict(
            color=["red" if v < 0 else "blue" for v in sorted_values]
        ),
        hoverinfo="text",  # íˆ´íŒ í™œì„±í™”
        text=tooltips  # íˆ´íŒ í…ìŠ¤íŠ¸ (íŠ¹ì„± ì œì™¸, SHAP ê°’ë§Œ)
    ))

    fig_bar.update_layout(
        # title="Feature Impact on Default Probability",
        xaxis=dict(
            title="ë¶€ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (%p)",
            zeroline=True,
            zerolinecolor="black",
            zerolinewidth=2
        ),
        yaxis=dict(
            title="Features",
            automargin=True
        ),
        height=500,
        width=700,
        margin=dict(l=150, r=50, t=50, b=50)
    )

    return fig_bar


# Streamlit í™”ë©´ ì¶œë ¥


def render_current_analysis(current_analysis):
    """
    Render the current analysis in a given column using cached charts.
    """
    # ê²Œì´ì§€ ì°¨íŠ¸
    st.subheader("Credit Probability and Grade")
    fig_gauge, proba, grade = create_gauge_chart(current_analysis)
    st.plotly_chart(fig_gauge, use_container_width=True)

    # ë¶€ë„ í™•ë¥  ë° ì‹ ìš©ë“±ê¸‰ ì •ë³´
    st.info(f"ë‹¹ì‚¬ì˜ ë¶€ë„í™•ë¥ ì€ {proba}%ì´ê³ , ì‹ ìš©ë“±ê¸‰ì€ {grade}ì— í•´ë‹¹í•©ë‹ˆë‹¤.")

    st.divider()

    # ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„
    st.subheader("Top Increasing and Decreasing Factors")
    fig_bar = create_bar_charts(current_analysis)
    st.plotly_chart(fig_bar, use_container_width=True)


# Streamlit í™”ë©´ ì¶œë ¥ í•¨ìˆ˜
def render_hypothetical_analysis(hypothetical_analysis, current_analysis):
    for scenario in hypothetical_analysis["scenarios"]:
        st.subheader(f"{scenario['id']} : {scenario['label']}")

        # Overview Chart (Vertical Bar Chart)
        overview_chart = create_scenario_overview_chart(scenario)
        st.plotly_chart(overview_chart, use_container_width=True)

        # Current vs. Hypothetical Chart (Horizontal Bar Chart)
        comparison_chart = create_current_vs_hypothetical_chart(
            current_analysis, scenario
        )
        st.plotly_chart(comparison_chart, use_container_width=True)

        # Divider for separation
        st.divider()


# 1. ì‹œë‚˜ë¦¬ì˜¤ ê°œìš”: Before vs. After (Vertical Bar Chart)
@st.cache_data
def create_scenario_overview_chart(scenario: Dict):
    before = scenario["before"]
    after = scenario["after"]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        name="Before",
        x=[scenario["label"]],
        y=[before["probability"]],
        marker=dict(color="red"),
        text=[f"Grade: {before['grade']}"],
        textposition="outside",
        hoverinfo="text"
    ))
    fig.add_trace(go.Bar(
        name="After",
        x=[scenario["label"]],
        y=[after["new_probability"]],
        marker=dict(color="green"),
        text=[f"Grade: {after['new_grade']}"],
        textposition="outside",
        hoverinfo="text"
    ))

    fig.update_layout(
        barmode="group",
        title="Default Probability: Before vs. After",
        xaxis=dict(title="Scenario"),
        yaxis=dict(title="Default Probability (%)", range=[0, 100]),
        height=400,
        margin=dict(l=50, r=50, t=50, b=50)
    )
    return fig


# 2. Current vs. Hypothetical Comparison (Horizontal Bar Chart)
@st.cache_data
def create_current_vs_hypothetical_chart(current_analysis: Dict, scenario: Dict):
    current_features = {f["feature"]: f["shap_value"]
                        for f in current_analysis["feature_impacts"]}
    hypothetical_features = scenario["after"]["top_influenced_features"]

    labels = [f["label"] for f in hypothetical_features]
    current_values = [current_features.get(
        f["feature"], 0) for f in hypothetical_features]
    new_values = [f["new_shap_value"] for f in hypothetical_features]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        name="Current SHAP Value",
        x=current_values,
        y=labels,
        orientation="h",
        marker=dict(color="blue"),
        text=[f"{v:.2f}" for v in current_values],
        textposition="auto",
        hoverinfo="text"
    ))
    fig.add_trace(go.Bar(
        name="New SHAP Value",
        x=new_values,
        y=labels,
        orientation="h",
        marker=dict(color="green"),
        text=[f"{v:.2f}" for v in new_values],
        textposition="auto",
        hoverinfo="text"
    ))

    fig.update_layout(
        barmode="group",
        title="Feature Impact: Current vs. Hypothetical",
        xaxis=dict(title="ë¶€ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (%p)"),
        yaxis=dict(title="Feature"),
        height=400,
        margin=dict(l=50, r=50, t=50, b=50)
    )
    return fig


def get_cached_analysis(company_index: str, analysis_type: str):
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        today = datetime.now()
        current_month = f"{today.year}-{today.month:02d}"

        query = """
        SELECT detailed_analysis, final_report
        FROM CREDIT_CONSULTING
        WHERE company_name = ? 
        AND analysis_type = ?
        AND strftime('%Y-%m', created_at) = ?
        ORDER BY created_at DESC
        LIMIT 1
        """

        cursor.execute(
            query, (f"Company_{company_index}", analysis_type, current_month))
        result = cursor.fetchone()
        conn.close()

        return result
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


@st.cache_data
def sample_generate():
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    X_test = pd.read_pickle(os.path.join(settings.DATA_PATH, 'X_test.pkl'))
    X_test.reset_index(inplace=True, drop=True)
    y_test = pd.read_pickle(os.path.join(settings.DATA_PATH, 'y_test.pkl'))
    y_test.reset_index(inplace=True, drop=True)

    # ëª¨ë¸ ë¡œë“œ
    booster = xgb.Booster()
    booster.load_model(os.path.join(settings.DATA_PATH, 'best_model.json'))
    model = xgb.XGBClassifier()
    model._Booster = booster
    model.n_classes_ = len(np.unique(y_test))

    # ì˜ˆì¸¡ ë° ìƒ˜í”Œë§
    probas = model.predict_proba(X_test)[:, 1]
    result_dfs = generate_sample_data(X_test, y_test, probas)
    return result_dfs[0], result_dfs[1], probas  # ì„¸ ê°œì˜ ê°’ì„ ë°˜í™˜


def generate_sample_data(X_test, y_test, probas):
    # ë¶€ë„ ê¸°ì—… (true positive) ìƒ˜í”Œë§
    true_positive_mask = (y_test.values == 1) & (probas >= 0.5)
    true_positive_indices = X_test.index[true_positive_mask]
    result_df = pd.DataFrame({
        'index': true_positive_indices,
        'actual': y_test[true_positive_indices],
        'predicted_proba': probas[true_positive_mask]
    }).sort_values('predicted_proba', ascending=False).sample(n=5, random_state=42)

    # ìƒì¡´ ê¸°ì—… (true negative) ìƒ˜í”Œë§
    true_negative_mask = (y_test.values == 0) & (probas < 0.5)
    true_negative_indices = X_test.index[true_negative_mask]
    result_df_0 = pd.DataFrame({
        'index': true_negative_indices,
        'actual': y_test[true_negative_indices],
        'predicted_proba': probas[true_negative_mask]
    }).sort_values('predicted_proba', ascending=False).sample(n=5, random_state=40)

    return result_df, result_df_0


def initialize_session_state():
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.preview_data = sample_generate()  # ìºì‹œëœ ë°ì´í„° ë¡œë“œ
        st.session_state.analysis_requested = False
        st.session_state.status_type = 'ë¶€ë„ ê¸°ì—…'
        st.session_state.company_index = "unknown"  # ì´ˆê¸°ê°’ ì„¤ì •
        st.session_state.analysis_type = "unknown"  # ì´ˆê¸°ê°’ ì„¤ì •
        st.session_state.analysis_result = None

        # ê¸°ì—… ìƒíƒœ ë³€ê²½ ì‹œ, ë¶„ì„ ìš”ì²­ ì´ˆê¸°í™”
        if "status_type" in st.session_state:
            st.session_state.analysis_requested = False


def submit_feedback(feedback_type, feedback_text):
    if not feedback_text:
        st.error("í”¼ë“œë°± ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    company_index = str(st.session_state.get("company_index", "unknown"))
    analysis_type = st.session_state.get("analysis_type", "unknown")

    # # ë””ë²„ê¹…: ì „ì†¡ ë°ì´í„° í™•ì¸
    # feedback_data = {
    #     "company_name": company_index,
    #     "feedback_type": feedback_type,
    #     "analysis_type": analysis_type,
    #     "feedback_text": feedback_text,
    # }
    # st.write("Feedback Data:", feedback_data)  # ë””ë²„ê¹… ì¶œë ¥

    try:

        payload = {
            "company_name": company_index,
            "feedback_type": feedback_type,
            "analysis_type": analysis_type,
            "feedback_text": feedback_text
        }

        with st.spinner("í”¼ë“œë°±ì„ ì œì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
            response = requests.post(
                "http://127.0.0.1:8000/credit_feedback/",
                json=payload
            )
            response.raise_for_status()  # HTTP ì—ëŸ¬ ê²€ì‚¬
            if response.status_code == 200:
                st.success("í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.balloons()
            else:
                st.error(f"í”¼ë“œë°± ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: {response.status_code}")
    except requests.exceptions.HTTPError as e:
        st.error(f"ì„œë²„ ì˜¤ë¥˜: {e.response.status_code} - {e.response.reason}")
    except requests.exceptions.RequestException as e:
        st.error(f"í”¼ë“œë°± ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


def main():

    initialize_session_state()

    # ì‚¬ì´ë“œë°” êµ¬ì„±
    with st.sidebar:
        st.title("ğŸ“ˆ ì‹ ìš©ì»¨ì„¤íŒ… ì„¤ì •")

        # form ë°–ì—ì„œ radio ë²„íŠ¼ êµ¬ì„±
        status_type = st.radio(
            "ê¸°ì—… ìƒíƒœ",
            options=["ë¶€ë„ ê¸°ì—…", "ìƒì¡´ ê¸°ì—…"],
            format_func=lambda x: "ë¶€ë„ ê¸°ì—…" if x == "ë¶€ë„ ê¸°ì—…" else "ìƒì¡´ ê¸°ì—…",
            key='status_type',
            on_change=lambda: st.session_state.update(
                {"analysis_requested": False})
        )

        # ë¶„ì„ ì„¤ì •ì„ ìœ„í•œ form
        with st.form("analysis_form"):  # ê³ ìœ  í‚¤: "analysis_form"
            result_df, result_df_0, probas = st.session_state.preview_data
            company_indices = result_df['index'].tolist(
            ) if status_type == "ë¶€ë„ ê¸°ì—…" else result_df_0['index'].tolist()

            selected_company = st.selectbox(
                "ê¸°ì—… ì„ íƒ",
                options=company_indices,
                format_func=lambda x: f"Company_{x} (ì˜ˆì¸¡í™•ë¥ : {probas[x]:.2%})"
            )

            analysis_type = st.radio(
                "ë¶„ì„ ë°©ì‹",
                options=["current", "hypothetical"],
                format_func=lambda x: "í˜„í™© ë¶„ì„" if x == "current" else "ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„"
            )

            submitted = st.form_submit_button("ë¶„ì„ ì‹œì‘")  # `key` ì œê±°
            if submitted:
                st.session_state.analysis_requested = True
                st.session_state.company_index = str(selected_company)
                st.session_state.analysis_type = analysis_type
                st.session_state.analysis_result = None

        if not st.session_state.get('analysis_requested', False):
            st.info("ğŸ‘† ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

        st.divider()
        st.header("ğŸ“ í”¼ë“œë°±")

        # í”¼ë“œë°± í¼ì€ í•­ìƒ í‘œì‹œ
        with st.form("credit_feedback_form", clear_on_submit=True):  # ê³ ìœ  í‚¤: "credit_feedback_form"
            feedback_type = st.radio(
                "í”¼ë“œë°± ìœ í˜•",
                options=["ê°œì„ ì‚¬í•­", "ì˜¤ë¥˜ì‹ ê³ ", "ê¸°íƒ€"],
                horizontal=True,
                key="feedback_type"
            )

            feedback_text = st.text_area(
                "ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”",
                placeholder="ë¶„ì„ ê²°ê³¼ë‚˜ ì‚¬ìš©ì„±ì— ëŒ€í•œ ì˜ê²¬ì„ ììœ ë¡­ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
                key="feedback_text"
            )

            submitted_feedback = st.form_submit_button("í”¼ë“œë°± ì œì¶œ")  # `key` ì œê±°

            # ì œì¶œ ì‹œ ë™ì‘
            if submitted_feedback:
                # if not st.session_state.get("analysis_requested", False):
                #     st.warning("ë¶„ì„ ì—†ì´ í”¼ë“œë°±ì„ ì œì¶œí–ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì‹œì‘í•œ í›„ ì œì¶œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                submit_feedback(feedback_type, feedback_text)

    # ìµœì¢… ë³´ê³ ì„œ í‘œì‹œ ë¶€ë¶„
    if not st.session_state.analysis_requested:
        st.title("ğŸ¤– AIê¸°ë°˜ ì‹ ìš©ë¶„ì„ ë¦¬í¬íŠ¸")
        st.markdown("""
        ### ğŸ‘‹ ì‚¬ìš© ë°©ë²•
        1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•˜ê³  ì‹¶ì€ ê¸°ì—…ì˜ ìƒíƒœë¥¼ ì„ íƒí•˜ì„¸ìš”
        2. ê¸°ì—… ëª©ë¡ì—ì„œ íŠ¹ì • ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš”
        3. ë¶„ì„ ìœ í˜•(í˜„í™©/ì‹œë®¬ë ˆì´ì…˜)ì„ ì„ íƒí•˜ì„¸ìš”
        4. 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        """)

        st.write('')
        st.divider()
        st.write('')

        st.success("ğŸ“¢ í˜„í™© ë¶„ì„ê³¼ ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„ì„ í†µí•´ ê¸°ì—…ì˜ ì‹ ìš© ìƒíƒœë¥¼ ì •í™•íˆ ì§„ë‹¨í•˜ê³  ê°œì„  ì „ëµì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ í˜„í™© ë¶„ì„ ë° ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„ ì„¤ëª…
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“Š **í˜„í™© ë¶„ì„**")
            st.write("""
            **í˜„í™© ë¶„ì„**ì€ íŠ¹ì • ê¸°ì—…ì˜ í˜„ì¬ ì‹ ìš© ìƒíƒœë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.  
            ë¶€ë„ í™•ë¥ ê³¼ ì‹ ìš© ë“±ê¸‰ì„ í™•ì¸í•˜ê³ , ë¶€ë„ ìœ„í—˜ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.  
            """)
            st.markdown("""
            **API ì •ë³´**:  
            - **ì—”ë“œí¬ì¸íŠ¸**: `/credit_analysis`  
            - **íŒŒë¼ë¯¸í„°**:  
                - `company_index`: ê¸°ì—… ì¸ë±ìŠ¤ (ìˆ«ì) 
                - `analysis_type`: `"current"`  
            """)

        with col2:
            st.subheader("ğŸ”„ **ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„**")
            st.write("""
            **ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„**ì€ íŠ¹ì • ìš”ì¸ì„ ë³€í™”ì‹œì¼°ì„ ë•Œ ì‹ ìš© ìƒíƒœê°€ ì–´ë–»ê²Œ ê°œì„ ë˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.  
            ê°€ì •ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ ë¶€ë„ í™•ë¥  ë° ì‹ ìš© ë“±ê¸‰ ë³€í™”ë¥¼ ì˜ˆì¸¡í•˜ê³  ì „ëµì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
            """)
            st.markdown("""
            **API ì •ë³´**:  
            - **ì—”ë“œí¬ì¸íŠ¸**: `/credit_analysis`  
            - **íŒŒë¼ë¯¸í„°**:  
                - `company_index`: ê¸°ì—… ì¸ë±ìŠ¤ (ìˆ«ì)
                - `analysis_type`: `"hypothetical"`  
            """)

    else:
        st.title("ğŸ“‘ ìµœì¢… ë³´ê³ ì„œ(ì•ˆ)")

        with st.status("ì‹ ìš©ë¶„ì„ ì§„í–‰ ì¤‘...", expanded=True) as status:
            st.toast("ğŸ” ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤")
            st.write("ìºì‹œ í™•ì¸ ì¤‘...")
            cached_result = get_cached_analysis(
                st.session_state.company_index,
                st.session_state.analysis_type
            )

            if cached_result:
                st.toast("ğŸ’¾ ìºì‹œëœ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤")
                st.write("ğŸ’¾ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤")
                detailed_analysis, final_report = cached_result
                result_dict = {
                    'detailed_analysis': detailed_analysis,
                    'final_report': final_report
                }
            else:
                st.toast("ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤")
                st.write("ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤")
                try:
                    payload = {
                        "company_index": st.session_state.company_index,
                        "analysis_type": st.session_state.analysis_type
                    }

                    response = requests.post(
                        f"http://127.0.0.1:8000/credit_analysis/",
                        json=payload
                    )
                    response.raise_for_status()
                    result_dict = response.json()
                    st.toast("âœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                except requests.exceptions.HTTPError as e:
                    st.error(
                        f"ì„œë²„ ì˜¤ë¥˜: {e.response.status_code} - {e.response.reason}")
                    return
                except requests.exceptions.RequestException as e:
                    st.error(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    return

        expander = st.expander("ë¶„ì„ ë‚´ìš©", expanded=False)
        with expander:
            tab1, tab2 = st.tabs(["ğŸ“Š ìƒì„¸ ë¶„ì„", "ğŸ“ ë¶„ì„ í…œí”Œë¦¿"])

            with tab1:
                # st.write(result_dict.keys())
                st.markdown(result_dict['detailed_analysis'])

            with tab2:
                try:
                    # í˜„ì¬ ë¶„ì„ ìœ í˜•ì— ë”°ë¥¸ í…œí”Œë¦¿ íŒŒì¼ëª… ì„¤ì •
                    if st.session_state.analysis_type == "current":
                        template_file = "current_credit_template.txt"
                    else:
                        template_file = "hypothetical_credit_template.txt"

                    # í…œí”Œë¦¿ ë‚´ìš© ë¡œë“œ ë° í‘œì‹œ
                    template_content = os.path.join(
                        settings.PROMPTS_DIR, template_file)
                    st.code(load_prompt(template_content), language='yaml')

                except FileNotFoundError as e:
                    st.error(f"í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

        # with st.expander("ğŸ“œ ìƒì„¸ ë¶„ì„ ë³´ê¸°"):
        #     if "detailed_analysis" in result_dict and result_dict["detailed_analysis"]:
        #         st.write(result_dict["detailed_analysis"])
        #     else:
        #         st.warning("ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # 2ê°œì˜ ì—´ë¡œ êµ¬ì„±
        col1, col2 = st.columns(2)

        # ì™¼ìª½ ì—´: ìŠ¤íŠ¸ë¦¬ë° ë³´ê³ ì„œ
        with col1:
            # st.subheader("ğŸ“œ ìš”ì•½ ë³´ê³ ì„œ")
            st.subheader('')

            def stream_report():
                for line in result_dict['final_report'].split('\n'):
                    yield line + '\n'
                    time.sleep(0.2)

            st.write_stream(stream_report())
            status.update(label="ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

        # ì˜¤ë¥¸ìª½ ì—´: ì¶”ê°€ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        with col2:
            # st.subheader("ğŸ“Š ì‹œê°í™” ê²°ê³¼")
            # st.write("Fetching additional analysis from credit_query API...")
            st.subheader("")

            if st.session_state.analysis_type == "current":
                # current_analysis API í˜¸ì¶œ (ìºì‹±)
                current_analysis = fetch_credit_query(
                    company_index=st.session_state.company_index,
                    analysis_type="current"
                ).get("current_analysis", None)

                if current_analysis:
                    # render_current_analysisë¡œ ì°¨íŠ¸ì™€ ì •ë³´ë¥¼ ë Œë”ë§
                    render_current_analysis(current_analysis)
                else:
                    st.error("No current analysis data available.")
            else:
                # Hypothetical ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                hypothetical_analysis = fetch_credit_query(
                    company_index=st.session_state.company_index,
                    analysis_type="hypothetical"
                ).get("hypothetical_analysis", None)

                if not hypothetical_analysis:
                    st.error("No hypothetical analysis data available.")
                else:
                    # Current ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ë˜ëŠ” API í˜¸ì¶œ)
                    current_analysis = fetch_credit_query(
                        company_index=st.session_state.company_index,
                        analysis_type="current"
                    ).get("current_analysis", None)

                    if not current_analysis:
                        st.warning(
                            "Current analysis data not available. Fetching via API...")
                        try:
                            current_analysis = fetch_credit_query(
                                company_index=st.session_state.company_index,
                                analysis_type="current"
                            ).get("current_analysis", None)
                        except Exception as e:
                            st.error(
                                f"Error fetching current analysis data: {e}")
                            current_analysis = None

                    if current_analysis:
                        render_hypothetical_analysis(
                            hypothetical_analysis, current_analysis)
                    else:
                        st.error(
                            "Current analysis data could not be retrieved, comparison is unavailable.")
            # else:
            #     st.info("No additional analysis available for non-hypothetical type.")

            # # credit_query API í˜¸ì¶œ
            # try:
            #     analysis_type = st.session_state.analysis_type
            #     payload = {
            #         "company_index": st.session_state.company_index,
            #         "analysis_type": analysis_type
            #     }

            #     response = requests.post(
            #         f"http://127.0.0.1:8000/credit_query/",
            #         json=payload
            #     )
            #     response.raise_for_status()
            #     query_result = response.json()

            #     if analysis_type == "current":
            #         st.write("### Current Analysis")
            #         st.json(query_result.get("current_analysis", {}))
            #     elif analysis_type == "hypothetical":
            #         st.write("### Hypothetical Analysis")
            #         st.json(query_result.get("hypothetical_analysis", {}))

            # except requests.exceptions.HTTPError as e:
            #     st.error(
            #         f"credit_query ì„œë²„ ì˜¤ë¥˜: {e.response.status_code} - {e.response.reason}")
            # except requests.exceptions.RequestException as e:
            #     st.error(f"credit_query ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    main()
